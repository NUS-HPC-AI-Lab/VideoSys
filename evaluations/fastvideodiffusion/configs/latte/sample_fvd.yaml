# path:
pretrained_model_path: "maxin-cn/Latte-1"

# model config:
model: LatteT2V
video_length: 16
image_size: [512, 512]
# # beta schedule
beta_start: 0.0001
beta_end: 0.02
beta_schedule: "linear"
variance_type: "learned_range"

# model speedup
use_compile: False
use_fp16: True

# sample config:
seed: 0
run_time: 0
guidance_scale: 7.5
sample_method: 'DDIM'
num_sampling_steps: 50
enable_temporal_attentions: True
enable_vae_temporal_decoder: True # use temporal vae decoder from SVD, maybe reduce the video flicker (It's not widely tested)

# fvd
spatial_broadcast: True
spatial_threshold: [100, 800]
spatial_gap: 2
spatial_block: [0, 28]
temporal_broadcast: True
temporal_threshold: [100, 800]
temporal_gap: 4
cross_broadcast: True
cross_threshold: [80, 900]
cross_gap: 7
# diffusion_skip: False
# diffusion_skip_timestep: [1,1,1,0,0,0,0,0,0,0]

# eval
eval: True
eval_dataset: ./evaluations/fastvideodiffusion/datasets/webvid_selected.csv
save_img_path: "./evaluations/fastvideodiffusion/samples/latte/sample_fvd/"
